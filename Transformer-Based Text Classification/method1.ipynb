{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_version = \"subm9\"\n",
    "os.makedirs(model_version, exist_ok=True)\n",
    "\n",
    "# Model paths\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "output_dir = f\"./{model_version}/checkpoints\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/kaggle/input/win25-stat-528-kaggle-competition-1/train.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def make_dataset(df, train=True):    \n",
    "    sep_token = tokenizer.sep_token\n",
    "    df[\"ingredients\"] = df[\"ingredients\"].apply(lambda x: sep_token.join(eval(x)) if isinstance(x, str) else \"\")\n",
    "    df[\"description\"] = df[\"description\"].fillna(\"\")\n",
    "    \n",
    "    def make_text(row):\n",
    "        return f\"Name: {row['name']} {sep_token} Description: {row['description']} {sep_token} Ingredients: {row['ingredients']}\"\n",
    "\n",
    "    df[\"text\"] = df.apply(make_text, axis=1)\n",
    "\n",
    "    if train:\n",
    "        df[\"vegetarian\"] = df[\"vegetarian\"].astype(int)\n",
    "        dataset = Dataset.from_pandas(df[[\"text\", \"vegetarian\"]])\n",
    "    else:\n",
    "        dataset = Dataset.from_pandas(df[[\"text\"]])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = make_dataset(df)\n",
    "\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)  # DistilBertModel\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.pre_classifier = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[0][:, 0, :]\n",
    "        x = self.pre_classifier(pooled_output)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def tokenize_dataset(dataset, train=True):\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "    if train:\n",
    "        tokenized_dataset = tokenized_dataset.rename_column(\"vegetarian\", \"labels\")\n",
    "    tokenized_dataset.set_format(\"torch\")\n",
    "    return tokenized_dataset\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_dataset = tokenize_dataset(dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, eval_dataloader, criterion):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_valid_loss = eval_loss / len(eval_dataloader)\n",
    "    print(f\"Evaluation - Loss: {avg_valid_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    return avg_valid_loss, accuracy\n",
    "\n",
    "\n",
    "def train_fold(model, train_dataloader, eval_dataloader, optimizer, criterion, fold, num_epochs, eval_steps):\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    best_model_path = f\"{output_dir}/best_model_fold{fold}.pth\"\n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch+1} - Fold {fold}\")):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Store train loss\n",
    "            train_loss_history.append({\"epoch\": epoch+1, \"step\": step, \"train_loss\": loss.item()})\n",
    "\n",
    "            # Evaluate every 100 steps\n",
    "            if step > 0 and step % eval_steps == 0:\n",
    "                valid_loss, accuracy = evaluate(model, eval_dataloader, criterion)\n",
    "                valid_loss_history.append({\n",
    "                    \"epoch\": epoch+1,\n",
    "                    \"step\": step,\n",
    "                    \"valid_loss\": valid_loss,\n",
    "                    \"accuracy\": accuracy,\n",
    "                })\n",
    "\n",
    "                # Save model if validation loss improves\n",
    "                if epoch > 0 and valid_loss < best_valid_loss:\n",
    "                    best_valid_loss = valid_loss\n",
    "                    torch.save(model.state_dict(), best_model_path)\n",
    "                    print(f\"âœ… New best model saved for fold {fold} at step {step} with valid_loss {valid_loss:.4f}, accuracy {accuracy:.4f}\")\n",
    "    \n",
    "    # Save loss history\n",
    "    train_loss_df = pd.DataFrame(train_loss_history)\n",
    "    valid_loss_df = pd.DataFrame(valid_loss_history)\n",
    "    train_loss_df.to_csv(f\"{output_dir}/train_loss_fold{fold}.csv\", index=False)\n",
    "    valid_loss_df.to_csv(f\"{output_dir}/valid_loss_fold{fold}.csv\", index=False)\n",
    "\n",
    "    return best_model_path\n",
    "\n",
    "# 5-fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "fold_model_paths = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(tokenized_dataset)):\n",
    "    print(f\"\\nðŸ”¹ Training fold {fold+1}/5...\\n\")\n",
    "\n",
    "    # Split dataset into train and validation for this fold\n",
    "    train_subset = Subset(tokenized_dataset, train_idx)\n",
    "    valid_subset = Subset(tokenized_dataset, valid_idx)\n",
    "\n",
    "    train_dataloader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    eval_dataloader = DataLoader(valid_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize new model for each fold\n",
    "    model = BertClassifier(model_name=model_name, num_labels=2).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train and get best model path for this fold\n",
    "    best_model_path = train_fold(\n",
    "        model, train_dataloader, eval_dataloader, optimizer, criterion,\n",
    "        fold, num_epochs=3, eval_steps=100,\n",
    "    )\n",
    "    fold_model_paths.append(best_model_path)\n",
    "\n",
    "print(\"\\nðŸ† Best models saved for all folds:\", fold_model_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls \"/kaggle/working/subm9/checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fold_model_paths = [\n",
    "    \"best_model_fold0.pth\",\n",
    "    \"best_model_fold1.pth\",\n",
    "    \"best_model_fold2.pth\",\n",
    "    \"best_model_fold3.pth\",\n",
    "    \"best_model_fold4.pth\",\n",
    "]\n",
    "fold_model_paths = [f\"/kaggle/working/{model_version}/checkpoints/\" + each for each in fold_model_paths]\n",
    "\n",
    "\n",
    "def predict_ensemble(test_dataloader, model_paths, model_name, device):\n",
    "    all_fold_preds = []\n",
    "\n",
    "    for model_path in model_paths:\n",
    "        print(f\"Loading model from {model_path}...\")\n",
    "        \n",
    "        # Load model\n",
    "        model = BertClassifier(model_name=model_name, num_labels=2).to(device)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "\n",
    "        fold_preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_dataloader, desc=f\"Predicting with {model_path}\"):\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                preds = torch.argmax(outputs, dim=-1)  # Get predicted class (0 or 1)\n",
    "                fold_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        all_fold_preds.append(fold_preds)\n",
    "\n",
    "    # Majority voting\n",
    "    final_preds = []\n",
    "    for i in range(len(all_fold_preds[0])):\n",
    "        votes = [all_fold_preds[f][i] for f in range(len(model_paths))]\n",
    "        final_preds.append(Counter(votes).most_common(1)[0][0])\n",
    "\n",
    "    return np.array(final_preds)\n",
    "\n",
    "# Load test dataset\n",
    "test_file_path = \"/kaggle/input/win25-stat-528-kaggle-competition-1/test.csv\"\n",
    "df_test = pd.read_csv(test_file_path)\n",
    "dataset_test = make_dataset(df_test, train=False)\n",
    "\n",
    "# Tokenize test dataset\n",
    "# tokenized_test_dataset = tokenize_dataset(dataset_test)\n",
    "tokenized_test_dataset = tokenize_dataset(dataset_test, train=False)\n",
    "test_dataloader = DataLoader(tokenized_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Make ensemble predictions\n",
    "final_predictions = predict_ensemble(test_dataloader, fold_model_paths, model_name, device)\n",
    "\n",
    "# Save predictions\n",
    "submission_df = pd.DataFrame({\"id\": df_test.id, \"vegetarian\": final_predictions})\n",
    "submission_file = f\"{model_version}/submission.csv\"\n",
    "submission_df.to_csv(submission_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!head -n10 subm9/submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "\n",
    "for fold in range(num_folds):\n",
    "    # Load the data for the current fold\n",
    "    train_df = pd.read_csv(f\"subm9/checkpoints/train_loss_fold{fold}.csv\")\n",
    "    valid_df = pd.read_csv(f\"subm9/checkpoints/valid_loss_fold{fold}.csv\")\n",
    "\n",
    "    # Compute cumulative step for train and valid\n",
    "    train_df[\"cum_step\"] = train_df.index + 1  # Simple cumulative step index\n",
    "    valid_df[\"cum_step\"] = (valid_df.index + 1) * 100  # Valid recorded every 100 steps\n",
    "\n",
    "    # Get epoch start positions\n",
    "    epoch_start_steps = train_df.groupby(\"epoch\")[\"cum_step\"].first().values\n",
    "    epoch_labels = train_df[\"epoch\"].unique()\n",
    "\n",
    "    # Interpolate train loss at validation steps\n",
    "    train_interp_loss = np.interp(valid_df[\"cum_step\"], train_df[\"cum_step\"], train_df[\"train_loss\"])\n",
    "\n",
    "    # Create a new figure for each fold\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot train loss\n",
    "    plt.plot(train_df[\"cum_step\"], train_df[\"train_loss\"], label=\"Train Loss\", color=\"blue\", alpha=0.5, linewidth=0.5)\n",
    "    \n",
    "    # Plot interpolated train loss at validation steps\n",
    "    plt.plot(valid_df[\"cum_step\"], train_interp_loss, label=\"Interpolated Train Loss\", color=\"blue\", linestyle=\"dotted\", linewidth=2)\n",
    "\n",
    "    # Plot valid loss\n",
    "    plt.plot(valid_df[\"cum_step\"], valid_df[\"valid_loss\"], label=\"Valid Loss\", color=\"orange\", marker=\"o\", linestyle=\"dashed\", linewidth=2)\n",
    "\n",
    "    # Add vertical lines for epoch transitions\n",
    "    for i, step in enumerate(epoch_start_steps):\n",
    "        plt.axvline(x=step, color=\"gray\", linestyle=\"--\", alpha=0.8)\n",
    "        plt.text(step, plt.ylim()[1] * 0.95, f\"Epoch {epoch_labels[i]}\", color=\"black\", fontsize=10, rotation=90, verticalalignment=\"top\")\n",
    "\n",
    "    # Labels and title with increased font size\n",
    "    plt.xlabel(\"Step\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.title(f\"Training and Validation Loss - Fold {fold + 1}\", fontsize=16)\n",
    "\n",
    "    # Set tick label sizes\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Hide grid\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.legend(fontsize=12)  # Increase legend font size\n",
    "    plt.savefig(f'subm9/loss_plot_fold{fold + 1}.png')\n",
    "    plt.show()  # Show each figure separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "\n",
    "valid_losses = []\n",
    "accuracies = []\n",
    "\n",
    "for fold in range(num_folds):\n",
    "    # Load the validation loss data for the current fold\n",
    "    valid_df = pd.read_csv(f\"subm9/checkpoints/valid_loss_fold{fold}.csv\")\n",
    "\n",
    "    # Ensure the CSV contains the required columns\n",
    "    if \"valid_loss\" not in valid_df.columns or \"accuracy\" not in valid_df.columns:\n",
    "        raise ValueError(f\"Missing 'valid_loss' or 'accuracy' in valid_loss_fold{fold}.csv\")\n",
    "\n",
    "    # Get the best (lowest) validation loss and corresponding accuracy\n",
    "    best_valid_loss = valid_df[\"valid_loss\"].min()\n",
    "    best_accuracy = valid_df.loc[valid_df[\"valid_loss\"].idxmin(), \"accuracy\"]\n",
    "\n",
    "    valid_losses.append(best_valid_loss)\n",
    "    accuracies.append(best_accuracy)\n",
    "\n",
    "# Compute the average validation loss and accuracy across folds\n",
    "avg_valid_loss = np.mean(valid_losses)\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "\n",
    "print(f\"Average Validation Loss: {avg_valid_loss:.5f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fold_model_paths = [\n",
    "    \"best_model_fold0.pth\",\n",
    "    # \"best_model_fold1.pth\",\n",
    "    # \"best_model_fold2.pth\",\n",
    "    # \"best_model_fold3.pth\",\n",
    "    # \"best_model_fold4.pth\",\n",
    "]\n",
    "fold_model_paths = [f\"/kaggle/working/{model_version}/checkpoints/\" + each for each in fold_model_paths]\n",
    "\n",
    "# Load test dataset\n",
    "test_file_path = \"/kaggle/input/win25-stat-528-kaggle-competition-1/train.csv\"\n",
    "df_test = pd.read_csv(test_file_path)\n",
    "dataset_test = make_dataset(df_test, train=False)\n",
    "\n",
    "# Tokenize test dataset\n",
    "tokenized_test_dataset = tokenize_dataset(dataset_test, train=False)\n",
    "test_dataloader = DataLoader(tokenized_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Make ensemble predictions\n",
    "final_predictions = predict_ensemble(test_dataloader, fold_model_paths, model_name, device)\n",
    "df_test['prediction'] = final_predictions\n",
    "df_test['wrong'] = df_test.vegetarian != df_test.prediction\n",
    "df_test = pd.read_csv('/kaggle/working/subm9/wrong_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test.loc[df_test.wrong].head(10)[['vegetarian', 'prediction', 'name', 'description', 'ingredients']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6591796,
     "sourceId": 10645719,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
